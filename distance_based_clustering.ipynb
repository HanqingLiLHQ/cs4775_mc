{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c247097-9f91-4299-9cbf-c3ff3da096b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "dataset_path = os.path.join(os.getcwd(), \"dataset\")\n",
    "sys.path.insert(0, dataset_path)\n",
    "distance_based_clustering_path = os.path.join(os.getcwd(), \"distance_based_clustering\")\n",
    "sys.path.insert(1, distance_based_clustering_path)\n",
    "evaluate_path = os.path.join(os.getcwd(), \"evaluate\")\n",
    "sys.path.insert(2, evaluate_path)\n",
    "clustering_path = os.path.join(os.getcwd(), \"distance_based_clustering\", \"clustering\")\n",
    "sys.path.insert(3, clustering_path)\n",
    "import dbm\n",
    "import dataset_yeast_mini\n",
    "import fungi_mini\n",
    "import fungi\n",
    "import fungi_large\n",
    "import vertebrates_large\n",
    "import gapped\n",
    "from column_distance import *\n",
    "from distance_based_clustering.clustering import hierarchical_clustering\n",
    "from distance_based_clustering.clustering import kmeans_self_defined_dist\n",
    "from distance_based_clustering.clustering import kmeans_hier_init\n",
    "from distance_based_clustering.distance_matrix_calculation import pearson_distance\n",
    "from distance_based_clustering.distance_matrix_calculation import jensen_distance\n",
    "from distance_based_clustering.distance_matrix_calculation import dist_from_col\n",
    "from evaluate import ari_score\n",
    "from evaluate import fmi_score\n",
    "from evaluate import nmi_score\n",
    "from evaluate import graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f4ffc3-68c6-462d-912b-cc7e9d8df020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "\n",
    "def assign_unique_numbers_to_values(dataset):\n",
    "    \"\"\"\n",
    "    Assign unique numbers to the values in the dataset dictionary.\n",
    "    If two values are the same, they will be given the same number.\n",
    "\n",
    "    :param dataset: dict, a dictionary with values that need unique numbers assigned.\n",
    "    :return: dict, a dictionary with values replaced by unique numbers.\n",
    "    \"\"\"\n",
    "    unique_values = set(dataset.values())  # Get the unique values\n",
    "    value_to_number = {\n",
    "        value: idx for idx, value in enumerate(unique_values)\n",
    "    }  # Map each unique value to a number\n",
    "\n",
    "    return {key: value_to_number[value] for key, value in dataset.items()}\n",
    "\n",
    "\n",
    "def generate_labels_from_clusters(clusters):\n",
    "    \"\"\"\n",
    "    Generate a dictionary of labels based on cluster membership.\n",
    "    Items in the same list receive the same label, starting from 0.\n",
    "\n",
    "    :param clusters: list of lists, where each sublist represents a cluster.\n",
    "    :return: dict, a dictionary with items as keys and their respective labels as values.\n",
    "    \"\"\"\n",
    "    label_dict = {}\n",
    "    for label, cluster in enumerate(clusters):\n",
    "        for item in cluster:\n",
    "            label_dict[item] = label\n",
    "    return label_dict\n",
    "\n",
    "\n",
    "def create_cluster_dicts(clusters, dataset):\n",
    "    \"\"\"\n",
    "    Create a list of dictionaries for each cluster.\n",
    "\n",
    "    :param clusters: A list of clusters, each cluster being a list of item keys.\n",
    "    :param dataset: The dataset containing the items and their corresponding data.\n",
    "    :return: A list of dictionaries, each dictionary representing a cluster.\n",
    "    \"\"\"\n",
    "    our_cluster = []\n",
    "    for cluster in clusters:\n",
    "        cluster_dict = {}\n",
    "        for item in cluster:\n",
    "            cluster_dict[item] = dataset.mmm[item]\n",
    "        our_cluster.append(cluster_dict)\n",
    "    return our_cluster\n",
    "\n",
    "def create_random_subdatasets(original_dataset, subdataset_sizes, retain_cluster_structure=False):\n",
    "    # Flatten the original dataset\n",
    "    flattened_dataset = [item for cluster in original_dataset for item in cluster]\n",
    "\n",
    "    subdatasets = []\n",
    "\n",
    "    for size in subdataset_sizes:\n",
    "        if size > len(flattened_dataset):\n",
    "            raise ValueError(f\"Requested subdataset size {size} is larger than the total number of elements.\")\n",
    "\n",
    "        # Randomly select elements for the subdataset\n",
    "        subdataset = random.sample(flattened_dataset, size)\n",
    "\n",
    "        # Reshape into the original format, if required\n",
    "        if retain_cluster_structure:\n",
    "            reshaped_subdataset = []\n",
    "            temp = subdataset.copy()\n",
    "            for cluster in original_dataset:\n",
    "                cluster_size = len(cluster)\n",
    "                reshaped_subdataset.append(temp[:cluster_size])\n",
    "                temp = temp[cluster_size:]\n",
    "            subdataset = reshaped_subdataset\n",
    "\n",
    "        subdatasets.append(subdataset)\n",
    "\n",
    "    return subdatasets\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "class TreeNode(object):\n",
    "    \"\"\"\n",
    "    Data structure for the hierarchical tree. \n",
    "    This object is either an inner node or a leaf. \n",
    "    If it is an inner node:\n",
    "    both left and right attributes should be another treenode object.\n",
    "    height > 0. name should be \"inner#\". mn (member number)\n",
    "    If it is a leaf:\n",
    "    Both left and right attribute should be None.\n",
    "    Height = 0. name should be a specific motif id. \n",
    "    mn = 1\n",
    "    \"\"\"\n",
    "    def __init__(self, name, left_child, right_child, height, mn):\n",
    "        self.left = left_child\n",
    "        self.right = right_child\n",
    "        self.name = name\n",
    "        self.mn = mn\n",
    "        self.height = height\n",
    "        # if this is an innernode: \n",
    "        if self.left != None: \n",
    "            assert self.height > 0\n",
    "            assert self.left.height <= self.height\n",
    "            assert self.right.height <= self.height\n",
    "\n",
    "\n",
    "# This algorithm will first build a tree represented by class \"TreeNode\", then traverse the treenode\n",
    "# for heights from highest to the lowest until it finds k-1 nodes. After neglecting these top n-1 nodes, \n",
    "# the rest tree nodes just represents how to group the motifs into clusters. \n",
    "\n",
    "def wrap_dm(idlist, dm):\n",
    "    \"\"\"\n",
    "    helper functions to first wrap the motif idlist into a leaf list, and to convert the distance matrix into a distance map. \n",
    "    Precondition: \n",
    "        idlist: a list of motif ids. \n",
    "        dm: a np array representing the distance matrix. it should have a shape of len(idlist) * len(idlist)\n",
    "    Returns:\n",
    "        nodemap: a map of treenodes: treenode.name -> treenode\n",
    "        distance_map: a map of treenode.name -> treenode.name -> distance\n",
    "    \"\"\"\n",
    "    nodemap = {id : TreeNode(id, None, None, 0, 1) for id in idlist}\n",
    "    distance_map = {}\n",
    "    for i in range(len(idlist)):\n",
    "        motif_id1 = idlist[i]\n",
    "        id1_map = {}\n",
    "        for j in range(len(idlist)):\n",
    "            id1_map[idlist[j]] = dm[i][j]\n",
    "        distance_map[motif_id1] = id1_map\n",
    "    return nodemap, distance_map\n",
    "\n",
    "def shortest(dm):\n",
    "    \"\"\"\n",
    "    helper function that finds the shortest distance between two different nodes in a distance map.\n",
    "    Returns the shortest distance as well as the two TreeNode.names\n",
    "    Precondition:\n",
    "        dm: a map of treenode.name -> treenode.name -> distance\n",
    "    \"\"\"\n",
    "    ret = (None, None, np.inf)\n",
    "    for key1 in dm.keys():\n",
    "        for key2 in dm[key1].keys():\n",
    "            if key1 != key2 and dm[key1][key2] < ret[2]:\n",
    "                ret = [key1, key2, dm[key1][key2]]\n",
    "    return ret\n",
    "\n",
    "def tree_construction(dm, idlist, dc = \"complete\"):\n",
    "    \"\"\"\n",
    "    Returns a TreeNode object denoting the current tree\n",
    "    Precondition: \n",
    "        idlist: a list of motif ids. \n",
    "        dm: a np array representing the distance matrix. it should have a shape of len(idlist) * len(idlist)\n",
    "        dc: the way for distance update method. Should be one of \"complete\", \"single\", \"UPGMA\", \"WPGMA:\n",
    "    \"\"\"\n",
    "    nodemap, dm = wrap_dm(idlist,dm)\n",
    "    # need to build treenode for len(list(nodemap.keys()))-1 times\n",
    "    for iter in range(len(list(nodemap.keys()))-1):\n",
    "        m1, m2, sd = shortest(dm)\n",
    "        \n",
    "        # create the new node and update the nodemap\n",
    "        new_node_name = iter\n",
    "        left_node = nodemap[m1]\n",
    "        right_node = nodemap[m2]\n",
    "        lmn = left_node.mn\n",
    "        rmn = right_node.mn\n",
    "        mn = lmn + rmn\n",
    "        height = sd / 2\n",
    "        new_node = TreeNode(name = new_node_name, left_child = left_node, right_child = right_node, height = height, mn = mn)\n",
    "        nodemap[new_node_name] = new_node \n",
    "        del nodemap[m1]\n",
    "        del nodemap[m2]\n",
    "\n",
    "        # update the distance matrix\n",
    "        del dm[m1]\n",
    "        del dm[m2]\n",
    "        new_node_distances = {new_node_name : 0}\n",
    "        for m in dm.keys():\n",
    "            distance_l = dm[m][m1]\n",
    "            distance_r = dm[m][m2]\n",
    "            del dm[m][m1]\n",
    "            del dm[m][m2]\n",
    "            if dc == \"single\":\n",
    "                new_distance = min(distance_l, distance_r)\n",
    "            elif dc == \"complete\":\n",
    "                new_distance = max(distance_l, distance_r)\n",
    "            elif dc == \"UPGMA\":\n",
    "                new_distance = (distance_l * lmn + distance_r * rmn ) / mn\n",
    "            elif dc == \"WPGMA\":\n",
    "                new_distance = (distance_l + distance_r) / 2\n",
    "            dm[m][new_node_name] = new_distance\n",
    "            new_node_distances[m] = new_distance\n",
    "        dm[new_node_name] = new_node_distances\n",
    "    assert len(list(nodemap.keys())) == 1\n",
    "    return list(nodemap.values())[0]\n",
    "            \n",
    "        \n",
    "\n",
    "def cut_tree(tree, nclusters):\n",
    "    \"\"\"\n",
    "    Cut the given tree object to give nclusters\n",
    "    Precondition: \n",
    "        tree is a TreeNode object\n",
    "        nclusters is an integer >= 1\n",
    "    \"\"\"\n",
    "    height_map = {tree.height : [tree]}\n",
    "    remaining_steps = nclusters - 1\n",
    "    while remaining_steps > 0:\n",
    "        # find the highest node and split it into two child tree nodes\n",
    "        # there might still be a need to handle the really rare case that actually two nodes are at the same height\n",
    "        highest = max(list(height_map.keys()))\n",
    "        highest_node = height_map[highest][0]\n",
    "        if len(height_map[highest]) > 1:\n",
    "            height_map[highest].pop(0)\n",
    "        else:\n",
    "            del height_map[highest]\n",
    "        left_node = highest_node.left\n",
    "        right_node = highest_node.right\n",
    "        if left_node.height not in height_map: \n",
    "            height_map[left_node.height] = [left_node]\n",
    "        else:\n",
    "            height_map[left_node.height].append(left_node)\n",
    "        if right_node.height not in height_map: \n",
    "            height_map[right_node.height] = [right_node]\n",
    "        else:\n",
    "            height_map[right_node.height].append(right_node)\n",
    "        remaining_steps -= 1\n",
    "    node_clusters = []\n",
    "    for height in height_map.keys():\n",
    "        node_clusters += height_map[height]\n",
    "    assert len(node_clusters) == nclusters\n",
    "    # now it is just to get the motif names from the TreeNode objects\n",
    "    def degradenode(treenode):\n",
    "        \"\"\"\n",
    "        helper function to degrade the nodes from the treeNode objects\n",
    "        \"\"\"\n",
    "        if treenode.left == None:\n",
    "            return [treenode.name]\n",
    "        return degradenode(treenode.left) + degradenode(treenode.right)\n",
    "    clusters = []\n",
    "    for node in node_clusters:\n",
    "        clusters.append(degradenode(node))\n",
    "    return clusters\n",
    "    \n",
    "\n",
    "def hc(nclusters, dm, idlist, distance_update = \"UPGMA\"):\n",
    "    \"\"\"\n",
    "    Grow a tree, then cut it!\n",
    "    Preconditions:\n",
    "        nclusters: an integer >= 1\n",
    "        dm: np array for the distance matrix\n",
    "        idlist: the motif ids\n",
    "        distance_update: one of [\"complete\", \"single\", \"UPGMA\", \"WPGMA\"]\n",
    "    \"\"\"\n",
    "    return cut_tree(tree_construction(dm, idlist, dc = distance_update), nclusters)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed6b2c2-ae39-4328-b49f-8dbf51833778",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "\n",
    "# Dataset: Gapped vertebrates\n",
    "\n",
    "dataset = gapped.DNABindingMotifs()\n",
    "# dataset.mmm is a dictionary with format {\"id\": Bio.motifs.Motif object}\n",
    "# where each motif matrix can be retrieved by motif.pssm\n",
    "\n",
    "print(dataset.mmm)\n",
    "print(\"Finish printing dataset \\n\")\n",
    "\n",
    "dm, idlist = dist_from_col.calculate_distance_matrix(\n",
    "    dataset, Pearson_CC_Distance, \"expand\", bg=[0.25, 0.25, 0.25, 0.25], average=np.mean\n",
    ")\n",
    "# dm, idlist = jensen_distance.calculate_distance_matrix(dataset)\n",
    "\n",
    "dataset_cc = dataset.cc\n",
    "print(dataset_cc)\n",
    "print(\"Finish printing dataset cc \\n\")\n",
    "\n",
    "# base_dir = \"nature_clusters\"\n",
    "# generator = graph.MotifGraphGenerator(dataset_cc, base_dir)\n",
    "# cluster_paths = generator.generate_cluster_graphs()\n",
    "# generator.generate_final_composite_graph(cluster_paths)\n",
    "\n",
    "# Convert dataset_cc into a list of lists, where each inner list contains the keys of the corresponding dictionary\n",
    "dataset_cc_list = [[key for key in d] for d in dataset_cc]\n",
    "print(dataset_cc_list)\n",
    "print(\"Finish printing dataset cc list \\n\")\n",
    "\n",
    "# K-means clustering\n",
    "# One advantage of K-means is it can customize number of clusters needed\n",
    "num_clusters = len(dataset_cc_list)  # Define the number of clusters\n",
    "print(num_clusters)\n",
    "print(\"Finish printing num_clusters \\n\")\n",
    "\n",
    "clusters = hc(num_clusters, dm, idlist, distance_update=\"UPGMA\")\n",
    "print(clusters)\n",
    "print(\"Finish printing result by K-means \\n\")\n",
    "\n",
    "our_cluster = create_cluster_dicts(clusters, dataset)\n",
    "\n",
    "print(our_cluster)\n",
    "print(\"Finish printing our cluster \\n\")\n",
    "\n",
    "# base_dir_our = \"predicted_clusters\"\n",
    "# generator_our = graph.MotifGraphGenerator(our_cluster, base_dir_our)\n",
    "# cluster_paths_our = generator_our.generate_cluster_graphs()\n",
    "# generator_our.generate_final_composite_graph(cluster_paths_our)\n",
    "\n",
    "\n",
    "# clusters = kmeans_self_defined_dist.kmeans_motifs(dm, idlist, num_clusters)\n",
    "\n",
    "\n",
    "dataset_dic = dict(sorted(generate_labels_from_clusters(dataset_cc_list).items()))\n",
    "print(dataset_dic)\n",
    "print(\"Finish printing true labels \\n\")\n",
    "\n",
    "clusters_dic = dict(sorted(generate_labels_from_clusters(clusters).items()))\n",
    "print(clusters_dic)\n",
    "print(\"Finish printing predicted labels \\n\")\n",
    "\n",
    "true_labels = list(dataset_dic.values())\n",
    "predicted_labels = list(clusters_dic.values())\n",
    "\n",
    "score_ari = ari_score.evaluate_clustering(true_labels, predicted_labels)\n",
    "score_fmi = fmi_score.evaluate_clustering(true_labels, predicted_labels)\n",
    "score_nmi = nmi_score.evaluate_clustering(true_labels, predicted_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43366043-e11a-4571-bee4-8ed4103a8cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################################################################\n",
    "\n",
    "# # Dataset: fungi_large\n",
    "\n",
    "dataset2 = fungi_large.DNABindingMotifs()\n",
    "# dataset2.mmm is a dictionary with format {\"id\": Bio.motifs.Motif object}\n",
    "\n",
    "print(dataset2.mmm)\n",
    "print(\"Finish printing dataset2 \\n\")\n",
    "\n",
    "dm2, idlist2 = dist_from_col.calculate_distance_matrix(\n",
    "    dataset2, Euclidean_Distance, \"expand\", bg=[0.27, 0.23, 0.23, 0.27], average=np.mean\n",
    ")\n",
    "\n",
    "dataset2_cc = dataset2.cc\n",
    "print(dataset2_cc)\n",
    "print(\"Finish printing dataset2 cc \\n\")\n",
    "\n",
    "# base_dir2 = \"nature_clusters2\"\n",
    "# generator2 = graph.MotifGraphGenerator(dataset2_cc, base_dir2)\n",
    "# cluster_paths2 = generator2.generate_cluster_graphs()\n",
    "# generator2.generate_final_composite_graph(cluster_paths2)\n",
    "\n",
    "# Convert dataset2_cc into a list of lists, where each inner list contains the keys of the corresponding dictionary\n",
    "dataset2_cc_list = [[key for key in d] for d in dataset2_cc]\n",
    "print(dataset2_cc_list)\n",
    "print(\"Finish printing dataset2 cc list \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9df28ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical clustering\n",
    "# clusters = hierarchical_clustering.hierarchical_clustering(5, dm, idlist)\n",
    "# # resulting cluters after using clustering method\n",
    "# print(clusters)\n",
    "\n",
    "num_clusters2 = len(dataset2_cc_list)  # Define the number of clusters\n",
    "print(num_clusters2)\n",
    "print(\"Finish printing num_clusters2 \\n\")\n",
    "\n",
    "#clusters2 = hierarchical_clustering.hierarchical_clustering(num_clusters2, dm2, idlist2)\n",
    "clusters2 = kmeans_hier_init.kmeans_motifs(dm2, idlist2, num_clusters2)\n",
    "print(clusters2)\n",
    "print(\"Finish printing clustering result \\n\")\n",
    "our_cluster2 = create_cluster_dicts(clusters2, dataset2)\n",
    "\n",
    "# base_dir_our2 = \"predicted_clusters2\"\n",
    "# generator_our2 = graph.MotifGraphGenerator(our_cluster2, base_dir_our2)\n",
    "# cluster_paths_our2 = generator_our2.generate_cluster_graphs()\n",
    "# generator_our2.generate_final_composite_graph(cluster_paths_our2)\n",
    "\n",
    "\n",
    "dataset2_dic = dict(sorted(generate_labels_from_clusters(dataset2_cc_list).items()))\n",
    "print(dataset2_dic)\n",
    "print(\"Finish printing true labels \\n\")\n",
    "\n",
    "clusters2_dic = dict(sorted(generate_labels_from_clusters(clusters2).items()))\n",
    "print(clusters2_dic)\n",
    "print(\"Finish printing predicted labels \\n\")\n",
    "\n",
    "true_labels2 = list(dataset2_dic.values())\n",
    "predicted_labels2 = list(clusters2_dic.values())\n",
    "\n",
    "score_ari2 = ari_score.evaluate_clustering(true_labels2, predicted_labels2)\n",
    "score_fmi2 = fmi_score.evaluate_clustering(true_labels2, predicted_labels2)\n",
    "score_nmi2 = nmi_score.evaluate_clustering(true_labels2, predicted_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8768d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "\n",
    "Dataset: fungi\n",
    "\n",
    "dataset3 = fungi.DNABindingMotifs()\n",
    "# dataset3.mmm is a dictionary with format {\"id\": Bio.motifs.Motif object}\n",
    "\n",
    "print(dataset3.mmm)\n",
    "print(\"Finish printing dataset3 \\n\")\n",
    "\n",
    "dm3, idlist3 = dist_from_col.calculate_distance_matrix(\n",
    "    dataset3, Kullback_Leibler_Distance, \"expand\", bg=[0.27, 0.23, 0.23, 0.27], average=np.mean\n",
    ")\n",
    "\n",
    "dataset3_cc = dataset3.cc\n",
    "print(dataset3_cc)\n",
    "print(\"Finish printing dataset3 cc \\n\")\n",
    "\n",
    "# base_dir3 = \"nature_clusters3\"\n",
    "# generator3 = graph.MotifGraphGenerator(dataset3_cc, base_dir3)\n",
    "# cluster_paths3 = generator3.generate_cluster_graphs()\n",
    "# generator3.generate_final_composite_graph(cluster_paths3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a761048",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert dataset3_cc into a list of lists, where each inner list contains the keys of the corresponding dictionary\n",
    "dataset3_cc_list = [[key for key in d] for d in dataset3_cc]\n",
    "print(dataset3_cc_list)\n",
    "print(\"Finish printing dataset3 cc list \\n\")\n",
    "\n",
    "\n",
    "num_clusters3 = len(dataset3_cc_list)  # Define the number of clusters\n",
    "print(num_clusters3)\n",
    "print(\"Finish printing num_clusters3 \\n\")\n",
    "\n",
    "cluster3 = hc(num_clusters3, dm3, idlist3, distance_update=\"UPGMA\")\n",
    "print(cluster3)\n",
    "print(\"Finish printing result by hierarchical clustering \\n\")\n",
    "\n",
    "\n",
    "# cluster3 = kmeans_hier_init.kmeans_motifs(dm3, idlist3, num_clusters3)\n",
    "# print(cluster3)\n",
    "# print(\"Finish printing result by K means \\n\")\n",
    "\n",
    "our_cluster3 = create_cluster_dicts(cluster3, dataset3)\n",
    "\n",
    "# base_dir_our3 = \"predicted_clusters3\"\n",
    "# generator_our3 = graph.MotifGraphGenerator(our_cluster3, base_dir_our3)\n",
    "# cluster_paths_our3 = generator_our3.generate_cluster_graphs()\n",
    "# generator_our3.generate_final_composite_graph(cluster_paths_our3)\n",
    "\n",
    "\n",
    "dataset3_dic = dict(sorted(generate_labels_from_clusters(dataset3_cc_list).items()))\n",
    "print(dataset3_dic)\n",
    "print(\"Finish printing true labels \\n\")\n",
    "\n",
    "clusters3_dic = dict(sorted(generate_labels_from_clusters(cluster3).items()))\n",
    "print(clusters3_dic)\n",
    "print(\"Finish printing predicted labels \\n\")\n",
    "\n",
    "true_labels3 = list(dataset3_dic.values())\n",
    "predicted_labels3 = list(clusters3_dic.values())\n",
    "\n",
    "score_ari3 = ari_score.evaluate_clustering(true_labels3, predicted_labels3)\n",
    "score_fmi3 = fmi_score.evaluate_clustering(true_labels3, predicted_labels3)\n",
    "score_nmi3 = nmi_score.evaluate_clustering(true_labels3, predicted_labels3)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "print(score_ari3)\n",
    "print(score_fmi3)\n",
    "print(score_nmi3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6e5c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "\n",
    "Dataset: vertebrates_large\n",
    "\n",
    "dataset4 = vertebrates_large.DNABindingMotifs()\n",
    "# dataset4.mmm is a dictionary with format {\"id\": Bio.motifs.Motif object}\n",
    "\n",
    "print(dataset4.mmm)\n",
    "print(\"Finish printing dataset4 \\n\")\n",
    "\n",
    "dm4, idlist4 = dist_from_col.calculate_distance_matrix(\n",
    "    dataset4, Euclidean_Distance, \"expand\", bg=[0.25, 0.25, 0.25, 0.25], average=np.mean\n",
    ")\n",
    "\n",
    "dataset4_cc = dataset4.cc\n",
    "print(dataset4_cc)\n",
    "print(\"Finish printing dataset4 cc \\n\")\n",
    "\n",
    "# base_dir4 = \"nature_clusters4\"\n",
    "# generator4 = graph.MotifGraphGenerator(dataset4_cc, base_dir4)\n",
    "# cluster_paths4 = generator4.generate_cluster_graphs()\n",
    "# generator4.generate_final_composite_graph(cluster_paths4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162a37b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert dataset4_cc into a list of lists, where each inner list contains the keys of the corresponding dictionary\n",
    "dataset4_cc_list = [[key for key in d] for d in dataset4_cc]\n",
    "print(dataset4_cc_list)\n",
    "print(\"Finish printing dataset4 cc list \\n\")\n",
    "\n",
    "\n",
    "num_clusters4 = len(dataset4_cc_list)  # Define the number of clusters\n",
    "print(num_clusters4)\n",
    "print(\"Finish printing num_clusters4 \\n\")\n",
    "\n",
    "# cluster4 = hierarchical_clustering.hierarchical_clustering(num_clusters4, dm4, idlist4)\n",
    "# print(cluster4)\n",
    "# print(\"Finish printing result by hierarchical clustering \\n\")\n",
    "\n",
    "\n",
    "cluster4 = kmeans_hier_init.kmeans_motifs(dm4, idlist4, num_clusters4)\n",
    "print(cluster4)\n",
    "print(\"Finish printing result by K means \\n\")\n",
    "\n",
    "our_cluster4 = create_cluster_dicts(cluster4, dataset4)\n",
    "\n",
    "# base_dir_our3 = \"predicted_clusters3\"\n",
    "# generator_our3 = graph.MotifGraphGenerator(our_cluster3, base_dir_our3)\n",
    "# cluster_paths_our3 = generator_our3.generate_cluster_graphs()\n",
    "# generator_our3.generate_final_composite_graph(cluster_paths_our3)\n",
    "\n",
    "\n",
    "dataset4_dic = dict(sorted(generate_labels_from_clusters(dataset4_cc_list).items()))\n",
    "print(dataset4_dic)\n",
    "print(\"Finish printing true labels \\n\")\n",
    "\n",
    "clusters4_dic = dict(sorted(generate_labels_from_clusters(cluster4).items()))\n",
    "print(clusters4_dic)\n",
    "print(\"Finish printing predicted labels \\n\")\n",
    "\n",
    "true_labels4 = list(dataset4_dic.values())\n",
    "predicted_labels4 = list(clusters4_dic.values())\n",
    "\n",
    "score_ari4 = ari_score.evaluate_clustering(true_labels4, predicted_labels4)\n",
    "score_fmi4 = fmi_score.evaluate_clustering(true_labels4, predicted_labels4)\n",
    "score_nmi4 = nmi_score.evaluate_clustering(true_labels4, predicted_labels4)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "print(score_ari4)\n",
    "print(score_fmi4)\n",
    "print(score_nmi4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
